Loading and preprocessing data...

=== Model Training ===

=== Time Series Cross-Validation with LightGBM ===

--- Fold 1 ---
Training LightGBM model...
Original class distribution: {0: 5632, 1: 70}
Training set after sampling: Class distribution = {0: 5632, 1: 2816}
Resampled dataset size: 8448 (Positive: 2816, Negative: 5632)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[46]	train's auc: 0.999977	train's binary_logloss: 0.0191088	valid's auc: 0.707257	valid's binary_logloss: 0.080903
LightGBM AUC: 0.7073

--- Fold 2 ---
Training LightGBM model...
Original class distribution: {0: 11250, 1: 154}
Training set after sampling: Class distribution = {0: 11250, 1: 5625}
Resampled dataset size: 16875 (Positive: 5625, Negative: 11250)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[34]	train's auc: 0.999628	train's binary_logloss: 0.065511	valid's auc: 0.747835	valid's binary_logloss: 0.109955
LightGBM AUC: 0.7478

--- Fold 3 ---
Training LightGBM model...
Original class distribution: {0: 16884, 1: 222}
Training set after sampling: Class distribution = {0: 16884, 1: 8442}
Resampled dataset size: 25326 (Positive: 8442, Negative: 16884)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[15]	train's auc: 0.995722	train's binary_logloss: 0.213474	valid's auc: 0.718895	valid's binary_logloss: 0.260615
LightGBM AUC: 0.7189

--- Fold 4 ---
Training LightGBM model...
Original class distribution: {0: 22505, 1: 303}
Training set after sampling: Class distribution = {0: 22505, 1: 11252}
Resampled dataset size: 33757 (Positive: 11252, Negative: 22505)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[6]	train's auc: 0.98429	train's binary_logloss: 0.405424	valid's auc: 0.693888	valid's binary_logloss: 0.445811
LightGBM AUC: 0.6939

--- Fold 5 ---
Training LightGBM model...
Original class distribution: {0: 28123, 1: 387}
Training set after sampling: Class distribution = {0: 28123, 1: 14061}
Resampled dataset size: 42184 (Positive: 14061, Negative: 28123)
Training until validation scores don't improve for 50 rounds
Early stopping, best iteration is:
[32]	train's auc: 0.996408	train's binary_logloss: 0.113835	valid's auc: 0.775603	valid's binary_logloss: 0.161385
LightGBM AUC: 0.7756

Best model selected from fold 5 with AUC: 0.7756
Best parameters saved to results/lightgbm_best_params.json

=== Model Evaluation ===
Optimal threshold for recall: 0.1515

==== Injury Prediction Model Validation Set Performance ====
AUC: 0.8680
F1 Score: 0.0981
Precision: 0.0525
Accuracy: 0.8114
Specificity: 0.8122
Injury risk score(Recall): 0.7532
confusion_matrix: TN=27409, FP=6337, FN=115, TP=351

==== Injury Prediction Model Test Set Performance ====
AUC: 0.7443
F1 Score: 0.0775
Precision: 0.0415
Accuracy: 0.8080
Specificity: 0.8111
Injury risk score(Recall): 0.5897
confusion_matrix: TN=6843, FP=1594, FN=48, TP=69

=== Saving Results ===
Model and metadata saved to results/injury_prediction_model.pkl and results/injury_prediction_model_metadata.pkl

=== Final Model Performance ===
AUC: 0.7443
F1 Score: 0.0775
Injury Risk Score (Recall): 0.5897
Confusion Matrix:
  TP: 69
  FP: 1594
  FN: 48
  TN: 6843